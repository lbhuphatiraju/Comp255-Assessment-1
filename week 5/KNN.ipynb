{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training input done \n",
      "testing input done\n",
      "feature normlization done\n",
      "Accuracy:  0.7504798464491362\n",
      "[[ 43   3   0   0   0   1   0   0   0   0   7   3   0]\n",
      " [  3  54   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   3  48   1   2   0   1   0   0   0   1   1   0]\n",
      " [  2   0   2  84   4   5   1   1   0   0   0   0   0]\n",
      " [  0   0   1   8  36   7   1   3   0   0   1   0   0]\n",
      " [  1   1   2  14  26  32   4   1   1   0   1   2   0]\n",
      " [  1   0   6   4   2   6 191   4   5   0   0   0   0]\n",
      " [  0   0   1   0   0   2  14  21   1   0   0   0   0]\n",
      " [  0   0   0   1   0   1   9   2  24   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  96   0   0   0]\n",
      " [  0   0   1   3   2   7   2   0   0   0  58  27   0]\n",
      " [  0   0   1   1   0   0   0   0   0   0  39  59   0]\n",
      " [  0   0   0   1   0   0   1   0   0   0   0   0  36]]\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "df_training = pd.read_csv('training_data.csv', header=None)\n",
    "df_testing = pd.read_csv('testing_data.csv', header=None)\n",
    "\n",
    "y_train = df_training[df_training.shape[1] - 1].values\n",
    "    # Labels should start from 0 in sklearn\n",
    "y_train = y_train - 1\n",
    "\n",
    "\n",
    "y_train = y_train.astype(int)\n",
    "df_training = df_training.drop([df_training.shape[1] - 1], axis=1)\n",
    "X_train = df_training.values\n",
    "print (\"training input done \")\n",
    "y_test = df_testing[df_testing.shape[1] - 1].values\n",
    "y_test = y_test - 1\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "\n",
    "df_testing = df_testing.drop([df_testing.shape[1] - 1], axis=1)\n",
    "X_test = df_testing.values\n",
    "    \n",
    "print (\"testing input done\")\n",
    "\n",
    "# Feature normalization for improving the performance of machine learning models. In this example code, \n",
    "    # StandardScaler is used to scale original feature to be centered around zero. You could try other normalization methods.\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print (\"feature normlization done\")\n",
    "\n",
    " # Build KNN classifier, in this example code\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluation. when we train a machine learning model on training set, we should evaluate its performance on testing set.\n",
    "    # We could evaluate the model by different metrics. Firstly, we could calculate the classification accuracy. In this example\n",
    "    # code, when n_neighbors is set to 4, the accuracy achieves 0.757.\n",
    "y_pred = knn.predict(X_test)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "    # We could use confusion matrix to view the classification for each activity.\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Build KNN classifier, in this example code\n",
    "#tuned_parameters = [{'n_neighbors':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}]\n",
    "#acc_scorer = make_scorer(accuracy_score)\n",
    "#grid_obj  = GridSearchCV(KNeighborsClassifier(), tuned_parameters, cv=10, scoring=acc_scorer)\n",
    "#grid_obj  = grid_obj .fit(X_train, y_train)\n",
    "#clf = grid_obj.best_estimator_\n",
    "#print (\"some results\")\n",
    "#print('best clf:', clf)\n",
    "#clf.fit(X_train, y_train)\n",
    "#y_pred = clf.predict(X_test)\n",
    "#print(y_pred)\n",
    "#print(y_pred.shape, y_test.shape)\n",
    "\n",
    "#print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "#print(confusion_matrix(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
